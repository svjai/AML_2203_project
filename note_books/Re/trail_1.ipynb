{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1223e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "came\n",
      "<Response [200]>\n",
      "dd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define login credentials\n",
    "username = '910392'\n",
    "password = 'Jai@83209320'\n",
    "\n",
    "# Construct dictionary containing login credentials\n",
    "login_data = {\n",
    "    'username': username,\n",
    "    'password': password,\n",
    "    'submit': 'Log in'\n",
    "}\n",
    "\n",
    "# Define the login URL of the Moodle site\n",
    "login_url = 'https://moodle.cestarcollege.com/moodle/login/index.php'\n",
    "print('came')\n",
    "# Initialize session object\n",
    "session = requests.Session()\n",
    "\n",
    "# Send POST request to login URL with credentials\n",
    "response = session.post(login_url, data=login_data)\n",
    "\n",
    "# Check if login was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Define URL of the page you want to scrape after login (e.g., site news)\n",
    "    scrape_url = 'https://moodle.cestarcollege.com/moodle/mod/forum/view.php?id=647'\n",
    "\n",
    "    # Send GET request to access protected page after login\n",
    "    page_response = session.get(scrape_url)\n",
    "    print(page_response)\n",
    "\n",
    "    # Parse HTML content of the page using BeautifulSoup\n",
    "    if page_response.status_code == 200:\n",
    "        print('dd')\n",
    "        soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "        \n",
    "        # Scraping code here...\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the Moodle site.\")\n",
    "else:\n",
    "    print(\"Login failed. Please check your credentials.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da24ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data from page 1.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_site_news(url, username, password):\n",
    "    posts = []\n",
    "    page_number = 1\n",
    "    \n",
    "    # Session object to maintain login state\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Login URL\n",
    "    login_url = 'https://moodle.cestarcollege.com/moodle/login/index.php'\n",
    "    \n",
    "    # Login data\n",
    "    login_data = {\n",
    "        'username': username,\n",
    "        'password': password,\n",
    "        'submit': 'Log in'\n",
    "    }\n",
    "    \n",
    "    # Authenticate\n",
    "    login_response = session.post(login_url, data=login_data)\n",
    "    \n",
    "    if login_response.status_code != 200:\n",
    "        print(\"Login failed.\")\n",
    "        return posts\n",
    "    \n",
    "    # Scrape site news\n",
    "    while True:\n",
    "        # Construct URL for the current page\n",
    "        page_url = f\"{url}?page={page_number}\"\n",
    "        \n",
    "        # Send a GET request to the site news page\n",
    "        response = session.get(page_url)\n",
    "        \n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content of the page using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find the elements containing the site news posts\n",
    "            site_news = soup.find_all('h3')\n",
    "            \n",
    "            # If no site news posts are found, break out of the loop\n",
    "            if not site_news:\n",
    "                \n",
    "                print('sd')\n",
    "                break\n",
    "            \n",
    "            # Extract relevant information from each site news post\n",
    "            for post in site_news:\n",
    "                # Extract the title of the post\n",
    "                title = post.find('h2', class_='title').text.strip()\n",
    "                \n",
    "                # Extract the publication date of the post\n",
    "                date = post.find('span', class_='time').text.strip()\n",
    "                \n",
    "                # Extract the content of the post\n",
    "                content = post.find('div', class_='content').text.strip()\n",
    "                \n",
    "                # Store the extracted information in a dictionary\n",
    "                post_info = {'Title': title, 'Date': date, 'Content': content}\n",
    "                \n",
    "                # Append the dictionary to the list of posts\n",
    "                posts.append(post_info)\n",
    "            \n",
    "            # Increment the page number for the next iteration\n",
    "            page_number += 1\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from page {page_number}.\")\n",
    "            break\n",
    "    \n",
    "    return posts\n",
    "\n",
    "# Replace 'https://your-moodle-site-url/news/' with the actual URL of your Moodle site news page\n",
    "url = 'https://moodle.cestarcollege.com/moodle/mod/forum/view.php'\n",
    "\n",
    "# Replace 'your_username' and 'your_password' with your actual Moodle credentials\n",
    "username = '910392'\n",
    "password = 'Jai@83209320'\n",
    "\n",
    "all_posts = scrape_site_news(url, username, password)\n",
    "\n",
    "# Print all the posts scraped from the site news page\n",
    "for post in all_posts:\n",
    "    print(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "651723a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_site_news(url, username, password):\n",
    "    posts = []\n",
    "    page_number = 1\n",
    "    \n",
    "    # Session object to maintain login state\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Login URL\n",
    "    login_url = 'https://moodle.cestarcollege.com/moodle/login/index.php'\n",
    "    \n",
    "    # Login data\n",
    "    login_data = {\n",
    "        'username': username,\n",
    "        'password': password,\n",
    "        'submit': 'Log in'\n",
    "    }\n",
    "    \n",
    "    # Authenticate\n",
    "    login_response = session.post(login_url, data=login_data)\n",
    "    \n",
    "    if login_response.status_code != 200:\n",
    "        print(\"Login failed.\")\n",
    "        return posts\n",
    "    \n",
    "    # Scrape site news\n",
    "    while True:\n",
    "        # Construct URL for the current page\n",
    "        page_url = f\"{url}&page={page_number}\"\n",
    "        \n",
    "        # Send a GET request to the site news page\n",
    "        response = session.get(page_url)\n",
    "        \n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content of the page using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find the elements containing the site news posts\n",
    "            site_news = soup.find_all('div', class_='content node')\n",
    "            \n",
    "            # If no site news posts are found, break out of the loop\n",
    "            if not site_news:\n",
    "                break\n",
    "            \n",
    "            # Extract relevant information from each site news post\n",
    "            for post in site_news:\n",
    "                # Extract the title of the post\n",
    "                title = post.find('a', class_='title').text.strip()\n",
    "                \n",
    "                # Extract the publication date of the post\n",
    "                date = post.find('span', class_='time').text.strip()\n",
    "                \n",
    "                # Extract the link URL of the post\n",
    "                link_url = post.find('a', class_='title')['href']\n",
    "                \n",
    "                # Store the extracted information in a dictionary\n",
    "                post_info = {'Title': title, 'Date': date, 'Link': link_url}\n",
    "                \n",
    "                # Append the dictionary to the list of posts\n",
    "                posts.append(post_info)\n",
    "            \n",
    "            # Increment the page number for the next iteration\n",
    "            page_number += 1\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from page {page_number}.\")\n",
    "            break\n",
    "    \n",
    "    return posts\n",
    "\n",
    "# Replace 'https://moodle.cestarcollege.com/moodle/mod/forum/view.php?id=647' with the actual URL of your Moodle site news page\n",
    "url = 'https://moodle.cestarcollege.com/moodle/mod/forum/discuss.php?d=252092'\n",
    "\n",
    "# Replace '910392' and 'Jai@83209320' with your actual Moodle credentials\n",
    "username = '910392'\n",
    "password = 'Jai@83209320'\n",
    "\n",
    "all_posts = scrape_site_news(url, username, password)\n",
    "\n",
    "# Print all the posts scraped from the site news page\n",
    "for post in all_posts:\n",
    "    print(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd25890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div aria-live=\"polite\" class=\"toast-wrapper mx-auto py-0 fixed-top\" role=\"status\"></div>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d7fc94368310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Print all the posts scraped from the site news page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_posts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_site_news(url, username, password):\n",
    "    posts = []\n",
    "    page_number = 1\n",
    "    \n",
    "    # Session object to maintain login state\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Login URL\n",
    "    login_url = 'https://moodle.cestarcollege.com/moodle/login/index.php'\n",
    "    \n",
    "    # Login data\n",
    "    login_data = {\n",
    "        'username': username,\n",
    "        'password': password,\n",
    "        'submit': 'Log in'\n",
    "    }\n",
    "    \n",
    "    # Authenticate\n",
    "    login_response = session.post(login_url, data=login_data)\n",
    "    \n",
    "    if login_response.status_code != 200:\n",
    "        print(\"Login failed.\")\n",
    "        return posts\n",
    "    \n",
    "    # Scrape site news\n",
    "    while True:\n",
    "        html_text=requests.get(url).text\n",
    "#         print(html_text)\n",
    "        soup=BeautifulSoup(html_text,'lxml')\n",
    "        headings=soup.find('div')\n",
    "        print(headings)\n",
    "        break\n",
    " \n",
    "# Replace 'https://moodle.cestarcollege.com/moodle/mod/forum/view.php?id=647' with the actual URL of your Moodle site news page\n",
    "url = 'https://moodle.cestarcollege.com/moodle/mod/forum/view.php?id=647'\n",
    "\n",
    "# Replace '910392' and 'Jai@83209320' with your actual Moodle credentials\n",
    "username = '910392'\n",
    "password = 'Jai@83209320'\n",
    "\n",
    "all_posts = scrape_site_news(url, username, password)\n",
    "\n",
    "# Print all the posts scraped from the site news page\n",
    "for post in all_posts:\n",
    "    print(post)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd4f89",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=XVv6mJpFOb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911786d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
